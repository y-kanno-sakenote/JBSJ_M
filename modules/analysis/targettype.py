# modules/analysis/targettype.py
# -*- coding: utf-8 -*-
"""
å¯¾è±¡ç‰©ãƒ»ç ”ç©¶ã‚¿ã‚¤ãƒ— åˆ†æã‚¿ãƒ–ï¼ˆå®Œæˆç‰ˆï¼‰
- â‘  æ§‹æˆæ¯”ãƒ»ã‚¯ãƒ­ã‚¹é›†è¨ˆï¼šå¯¾è±¡ç‰© / ç ”ç©¶ã‚¿ã‚¤ãƒ—ã®ä»¶æ•°ã€ã‚¯ãƒ­ã‚¹ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
- â‘¡ çµŒå¹´ãƒˆãƒ¬ãƒ³ãƒ‰ï¼šå¹´ã”ã¨ã®ä»¶æ•°æ¨ç§»ã€å¯¾è±¡ã®æ¯”è¼ƒã€ç§»å‹•å¹³å‡ã‚ªãƒ—ã‚·ãƒ§ãƒ³
- â‘¢ å…±èµ·ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼šåŒä¸€è«–æ–‡å†…ã®å…±èµ·ï¼ˆå¯¾è±¡ç‰© / ç ”ç©¶ã‚¿ã‚¤ãƒ— / ä¸¡æ–¹ï¼‰ã‚’ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã§å¯è¦–åŒ–
  * é‡ã„å‡¦ç†ã¯ãƒ‡ã‚£ã‚¹ã‚¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆmodules/common/cache_utils.pyï¼‰ã§æ°¸ç¶šåŒ–
"""

from __future__ import annotations
import re
import itertools
from typing import List, Tuple, Dict, Set

import pandas as pd
import streamlit as st

# è¡¨ç¤ºé †ï¼ˆå›ºå®šï¼‰
TARGET_ORDER = [
    "æ¸…é…’","ãƒ“ãƒ¼ãƒ«","ãƒ¯ã‚¤ãƒ³","ç„¼é…","ã‚¢ãƒ«ã‚³ãƒ¼ãƒ«é£²æ–™","ç™ºé…µä¹³ãƒ»ä¹³è£½å“",
    "é†¤æ²¹","å‘³å™Œ","ç™ºé…µé£Ÿå“","è¾²ç”£ç‰©ãƒ»æœå®Ÿ","å‰¯ç”£ç‰©ãƒ»ãƒã‚¤ã‚ªãƒã‚¹","é…µæ¯ãƒ»å¾®ç”Ÿç‰©","ã‚¢ãƒŸãƒé…¸ãƒ»ã‚¿ãƒ³ãƒ‘ã‚¯è³ª","ãã®ä»–"
]
TYPE_ORDER = [
    "å¾®ç”Ÿç‰©ãƒ»éºä¼å­é–¢é€£","é†¸é€ å·¥ç¨‹ãƒ»è£½é€ æŠ€è¡“","å¿œç”¨åˆ©ç”¨ãƒ»é£Ÿå“é–‹ç™º","æˆåˆ†åˆ†æãƒ»ç‰©æ€§è©•ä¾¡",
    "å“è³ªè©•ä¾¡ãƒ»å®˜èƒ½è©•ä¾¡","æ­´å²ãƒ»æ–‡åŒ–ãƒ»çµŒæ¸ˆ","å¥åº·æ©Ÿèƒ½ãƒ»æ „é¤ŠåŠ¹æœ","çµ±è¨ˆè§£æãƒ»ãƒ¢ãƒ‡ãƒ«åŒ–",
    "ç’°å¢ƒãƒ»ã‚µã‚¹ãƒ†ãƒŠãƒ“ãƒªãƒ†ã‚£","ä¿å­˜ãƒ»å®‰å®šæ€§","ãã®ä»–ï¼ˆç ”ç©¶ã‚¿ã‚¤ãƒ—ï¼‰"
]

def _order_options(all_options: list[str], preferred: list[str]) -> list[str]:
    """preferredã«ã‚ã‚‹ã‚‚ã®ã¯ãã®é †ã§å…ˆé ­ã€ãã‚Œä»¥å¤–ã¯äº”åéŸ³/ã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆé †ã§å¾Œã‚ã¸"""
    s = set(all_options)
    head = [x for x in preferred if x in s]
    tail = sorted([x for x in all_options if x not in preferred])
    return head + tail

# --- Optional deps (ãªãã¦ã‚‚å‹•ã) ---
try:
    import plotly.express as px  # type: ignore
    HAS_PX = True
except Exception:
    HAS_PX = False

try:
    import networkx as nx  # type: ignore
    HAS_NX = True
except Exception:
    HAS_NX = False

try:
    from pyvis.network import Network  # type: ignore
    HAS_PYVIS = True
except Exception:
    HAS_PYVIS = False

# --- æ°¸ç¶šã‚­ãƒ£ãƒƒã‚·ãƒ¥IO ---
try:
    from modules.common.cache_utils import cache_csv_path, load_csv_if_exists, save_csv
    HAS_DISK_CACHE = True
except Exception:
    HAS_DISK_CACHE = False


# ========== ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ==========
_SPLIT_MULTI_RE = re.compile(r"[;ï¼›,ã€ï¼Œ/ï¼|ï½œ\sã€€]+")

def split_multi(s) -> List[str]:
    if not s:
        return []
    return [w.strip() for w in _SPLIT_MULTI_RE.split(str(s)) if w.strip()]

def norm_key(s: str) -> str:
    s = str(s or "").replace("\u00A0", " ")
    s = re.sub(r"\s+", " ", s).strip()
    return s.lower()

def col_contains_any(df_col: pd.Series, needles: List[str]) -> pd.Series:
    """åˆ—ã®æ–‡å­—åˆ—ã« needles ã®ã„ãšã‚Œã‹ãŒéƒ¨åˆ†ä¸€è‡´ï¼ˆå°æ–‡å­—ãƒ»ç©ºç™½æ­£è¦åŒ–ï¼‰"""
    if not needles:
        return pd.Series([True] * len(df_col), index=df_col.index)
    lo_needles = [norm_key(n) for n in needles]
    def _hit(v: str) -> bool:
        s = norm_key(v)
        return any(n in s for n in lo_needles)
    return df_col.fillna("").astype(str).map(_hit)

@st.cache_data(ttl=600, show_spinner=False)
def _year_min_max(df: pd.DataFrame) -> Tuple[int, int]:
    if "ç™ºè¡Œå¹´" not in df.columns:
        return (1980, 2025)
    y = pd.to_numeric(df["ç™ºè¡Œå¹´"], errors="coerce")
    if y.notna().any():
        return (int(y.min()), int(y.max()))
    return (1980, 2025)

def _apply_filters(df: pd.DataFrame,
                   y_from: int, y_to: int,
                   targets: List[str], types: List[str]) -> pd.DataFrame:
    use = df.copy()
    if "ç™ºè¡Œå¹´" in use.columns:
        y = pd.to_numeric(use["ç™ºè¡Œå¹´"], errors="coerce")
        use = use[(y >= y_from) & (y <= y_to) | y.isna()]
    if targets and "å¯¾è±¡ç‰©_top3" in use.columns:
        use = use[col_contains_any(use["å¯¾è±¡ç‰©_top3"], targets)]
    if types and "ç ”ç©¶ã‚¿ã‚¤ãƒ—_top3" in use.columns:
        use = use[col_contains_any(use["ç ”ç©¶ã‚¿ã‚¤ãƒ—_top3"], types)]
    return use


# ========= â‘  æ§‹æˆæ¯”ãƒ»ã‚¯ãƒ­ã‚¹é›†è¨ˆ =========
@st.cache_data(ttl=600, show_spinner=False)
def _count_series(df: pd.DataFrame, col: str) -> pd.Series:
    if col not in df.columns:
        return pd.Series(dtype=int)
    bags: List[str] = []
    for v in df[col].fillna(""):
        bags += split_multi(v)
    if not bags:
        return pd.Series(dtype=int)
    s = pd.Series(bags)
    return s.value_counts().sort_values(ascending=False)

@st.cache_data(ttl=600, show_spinner=False)
def _cross_counts(df: pd.DataFrame, col_a: str, col_b: str) -> pd.DataFrame:
    """AÃ—Bã®ã‚¯ãƒ­ã‚¹ä»¶æ•°ï¼ˆåŒä¸€è«–æ–‡å†…ã§å…¨çµ„åˆã›ã‚’ã‚«ã‚¦ãƒ³ãƒˆï¼‰"""
    if col_a not in df.columns or col_b not in df.columns:
        return pd.DataFrame(columns=["A", "B", "count"])
    rows = []
    for _, r in df.iterrows():
        As = list(dict.fromkeys(split_multi(r.get(col_a, ""))))
        Bs = list(dict.fromkeys(split_multi(r.get(col_b, ""))))
        for a in As:
            for b in Bs:
                rows.append((a, b))
    if not rows:
        return pd.DataFrame(columns=["A", "B", "count"])
    c = pd.DataFrame(rows, columns=["A", "B"]).value_counts().reset_index(name="count")
    return c.sort_values("count", ascending=False).reset_index(drop=True)


def _render_distribution_block(df: pd.DataFrame) -> None:
    st.markdown("### ğŸ“Š åˆ†å¸ƒï¼šå¯¾è±¡ç‰©ï¼ç ”ç©¶ã‚¿ã‚¤ãƒ— ã®ä»¶æ•°")

    # ---- å¯¾è±¡ç‰©é›†è¨ˆ ----
    tg_series = (
        df.get("å¯¾è±¡ç‰©_top3", pd.Series(dtype=str))
          .fillna("")
          .apply(lambda s: [w.strip() for w in re.split(r"[;ï¼›,ã€ï¼Œ/ï¼|ï½œ\sã€€]+", str(s)) if w.strip()])
    )
    tg_flat = [w for lst in tg_series for w in lst]
    tg_counts = pd.Series(tg_flat, dtype="object").value_counts()

    if tg_counts.empty:
        st.info("å¯¾è±¡ç‰©ã®é›†è¨ˆå¯¾è±¡ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    else:
        tg_df = tg_counts.reset_index()
        tg_df.columns = ["å¯¾è±¡ç‰©", "ä»¶æ•°"]
        tg_df = tg_df.sort_values("ä»¶æ•°", ascending=False)
        top_n = st.number_input("å¯¾è±¡ç‰©ã®è¡¨ç¤ºä»¶æ•°", min_value=5, max_value=100, value=20, step=5, key="tg_topn")
        tg_df_top = tg_df.head(int(top_n))

        try:
            import plotly.express as px  # é…å»¶import
            fig = px.bar(
                tg_df_top,
                x="å¯¾è±¡ç‰©",
                y="ä»¶æ•°",
                text_auto=True,
                title="å¯¾è±¡ç‰©ã®å‡ºç¾ä»¶æ•°ï¼ˆä¸Šä½ï¼‰",
            )
            fig.update_layout(margin=dict(l=10, r=10, t=40, b=10), height=420)
            st.plotly_chart(fig, use_container_width=True)
        except Exception:
            st.bar_chart(tg_df_top.set_index("å¯¾è±¡ç‰©")["ä»¶æ•°"])

    st.divider()

    # ---- ç ”ç©¶ã‚¿ã‚¤ãƒ—é›†è¨ˆ ----
    tp_series = (
        df.get("ç ”ç©¶ã‚¿ã‚¤ãƒ—_top3", pd.Series(dtype=str))
          .fillna("")
          .apply(lambda s: [w.strip() for w in re.split(r"[;ï¼›,ã€ï¼Œ/ï¼|ï½œ\sã€€]+", str(s)) if w.strip()])
    )
    tp_flat = [w for lst in tp_series for w in lst]
    tp_counts = pd.Series(tp_flat, dtype="object").value_counts()

    if tp_counts.empty:
        st.info("ç ”ç©¶ã‚¿ã‚¤ãƒ—ã®é›†è¨ˆå¯¾è±¡ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    else:
        tp_df = tp_counts.reset_index()
        tp_df.columns = ["ç ”ç©¶ã‚¿ã‚¤ãƒ—", "ä»¶æ•°"]
        tp_df = tp_df.sort_values("ä»¶æ•°", ascending=False)
        top_n_tp = st.number_input("ç ”ç©¶ã‚¿ã‚¤ãƒ—ã®è¡¨ç¤ºä»¶æ•°", min_value=5, max_value=100, value=20, step=5, key="tp_topn")
        tp_df_top = tp_df.head(int(top_n_tp))

        try:
            import plotly.express as px
            fig2 = px.bar(
                tp_df_top,
                x="ç ”ç©¶ã‚¿ã‚¤ãƒ—",
                y="ä»¶æ•°",
                text_auto=True,
                title="ç ”ç©¶ã‚¿ã‚¤ãƒ—ã®å‡ºç¾ä»¶æ•°ï¼ˆä¸Šä½ï¼‰",
            )
            fig2.update_layout(margin=dict(l=10, r=10, t=40, b=10), height=420)
            st.plotly_chart(fig2, use_container_width=True)
        except Exception:
            st.bar_chart(tp_df_top.set_index("ç ”ç©¶ã‚¿ã‚¤ãƒ—")["ä»¶æ•°"])


# ---- â‘ -2 è¿½åŠ ï¼šå¯¾è±¡ç‰©Ã—ç ”ç©¶ã‚¿ã‚¤ãƒ—ã®ã‚¯ãƒ­ã‚¹ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ï¼ˆå¹´ç¯„å›²ï¼‹æœ€å°ä»¶æ•°ãƒ•ã‚£ãƒ«ã‚¿ä»˜ãï¼‰----
def _render_cross_block(df: pd.DataFrame) -> None:
    st.markdown("### â‘ -2 å¯¾è±¡ç‰© Ã— ç ”ç©¶ã‚¿ã‚¤ãƒ—ï¼ˆã‚¯ãƒ­ã‚¹ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ï¼‰")

    ymin_all, ymax_all = _year_min_max(df)
    c1, c2 = st.columns([2, 1])
    with c1:
        y_from, y_to = st.slider(
            "å¯¾è±¡å¹´ï¼ˆç¯„å›²ï¼‰",
            min_value=ymin_all, max_value=ymax_all,
            value=(ymin_all, ymax_all),
            key="obj_cross_year",
        )
    with c2:
        min_cnt = st.number_input("è¡¨ç¤ºã™ã‚‹æœ€å°ä»¶æ•° (â‰¥)", min_value=1, max_value=50, value=3, step=1, key="obj_cross_min")

    # å¹´ãƒ•ã‚£ãƒ«ã‚¿ã ã‘è»½é‡ã«é©ç”¨
    use = _apply_filters(df, y_from, y_to, [], [])

    cross = _cross_counts(use, "å¯¾è±¡ç‰©_top3", "ç ”ç©¶ã‚¿ã‚¤ãƒ—_top3")
    if cross.empty:
        st.info("ã‚¯ãƒ­ã‚¹é›†è¨ˆã§ãã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    # æœ€å°ä»¶æ•°ã§ãƒ•ã‚£ãƒ«ã‚¿
    cross = cross[cross["count"] >= int(min_cnt)].copy()
    if cross.empty:
        st.info("ã“ã®é–¾å€¤ã§ã¯ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚é–¾å€¤ã‚’ä¸‹ã’ã¦ãã ã•ã„ã€‚")
        return

    # ãƒ”ãƒœãƒƒãƒˆï¼ˆè¡Œ=ç ”ç©¶ã‚¿ã‚¤ãƒ—ã€åˆ—=å¯¾è±¡ç‰©ï¼‰
    piv = cross.pivot(index="B", columns="A", values="count").fillna(0).astype(int)
    piv.index.name = "ç ”ç©¶ã‚¿ã‚¤ãƒ—"
    piv.columns.name = "å¯¾è±¡ç‰©"

    if HAS_PX:
        fig = px.imshow(
            piv,
            aspect="auto",
            color_continuous_scale="Blues",
            labels=dict(color="ä»¶æ•°"),
        )
        fig.update_layout(height=560, margin=dict(l=10, r=10, t=30, b=10))
        st.plotly_chart(fig, use_container_width=True)
    else:
        st.dataframe(piv, use_container_width=True)


# ========= â‘¡ çµŒå¹´ãƒˆãƒ¬ãƒ³ãƒ‰ =========
@st.cache_data(ttl=600, show_spinner=False)
def _yearly_counts(df: pd.DataFrame, col: str) -> pd.DataFrame:
    """å¹´Ã—é …ç›®ã®ä»¶æ•°ï¼ˆåŒä¸€è«–æ–‡å†…ã®é‡è¤‡ã¯1ä»¶ã¨ã—ã¦ã‚«ã‚¦ãƒ³ãƒˆï¼‰"""
    if col not in df.columns or "ç™ºè¡Œå¹´" not in df.columns:
        return pd.DataFrame(columns=["ç™ºè¡Œå¹´", col, "count"])
    rows = []
    for _, r in df.iterrows():
        y = pd.to_numeric(r.get("ç™ºè¡Œå¹´"), errors="coerce")
        if pd.isna(y):
            continue
        items = list(dict.fromkeys(split_multi(r.get(col, ""))))
        for it in items:
            rows.append((int(y), it))
    if not rows:
        return pd.DataFrame(columns=["ç™ºè¡Œå¹´", col, "count"])
    c = pd.DataFrame(rows, columns=["ç™ºè¡Œå¹´", col]).value_counts().reset_index(name="count")
    return c.sort_values(["ç™ºè¡Œå¹´", "count"], ascending=[True, False]).reset_index(drop=True)

def _render_trend_block(df: pd.DataFrame) -> None:
    st.markdown("### â‘¡ çµŒå¹´å¤‰åŒ–ï¼ˆãƒˆãƒ¬ãƒ³ãƒ‰ï¼‰")

    ymin_all, ymax_all = _year_min_max(df)
    c1, c2, c3 = st.columns([1, 1, 1])
    with c1:
        y_from, y_to = st.slider("å¯¾è±¡å¹´ï¼ˆç¯„å›²ï¼‰", min_value=ymin_all, max_value=ymax_all, value=(ymin_all, ymax_all), key="obj_trend_year")
    with c2:
        target_mode = st.selectbox("å¯¾è±¡", ["å¯¾è±¡ç‰©_top3","ç ”ç©¶ã‚¿ã‚¤ãƒ—_top3"], index=0, key="obj_trend_mode")
    with c3:
        ma = st.number_input("ç§»å‹•å¹³å‡ï¼ˆå¹´ï¼‰", min_value=1, max_value=7, value=1, step=1, key="obj_trend_ma")

    # å€™è£œã¨é¸æŠ
    # å€™è£œã¨é¸æŠ
    use = _apply_filters(df, y_from, y_to, [], [])

    # ç”Ÿã®å€™è£œã‚’æŠ½å‡º
    all_items_raw = sorted({
        t for v in use.get(target_mode, pd.Series(dtype=str)).fillna("")
        for t in split_multi(v)
    })

    # â˜… è¡¨ç¤ºé †ã‚’å›ºå®šï¼ˆå¯¾è±¡ç‰©/ç ”ç©¶ã‚¿ã‚¤ãƒ—ã§é †åºã‚’åˆ‡æ›¿ï¼‰
    if target_mode == "å¯¾è±¡ç‰©_top3":
        all_items = _order_options(all_items_raw, TARGET_ORDER)
    else:  # "ç ”ç©¶ã‚¿ã‚¤ãƒ—_top3"
        all_items = _order_options(all_items_raw, TYPE_ORDER)

    # multiselectï¼ˆè¡¨ç¤ºé †ãã®ã¾ã¾ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆé¸æŠã‚‚åŒé †ã§ä¸Šä½ã‹ã‚‰ï¼‰
    sel = st.multiselect(
        "è¡¨ç¤ºã™ã‚‹é …ç›®ï¼ˆè¤‡æ•°å¯ï¼‰",
        all_items[:1000],
        default=all_items[: min(0, len(all_items))],
        key="obj_trend_items",
    )

    yearly = _yearly_counts(use, target_mode)
    if yearly.empty:
        st.info("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    piv = yearly.pivot_table(index="ç™ºè¡Œå¹´", columns=target_mode, values="count", aggfunc="sum").fillna(0).sort_index()
    if sel:
        piv = piv[[c for c in sel if c in piv.columns]]

    # â˜… ç©ºåˆ—ï¼ˆå…¨è§£é™¤ã‚„ä¸ä¸€è‡´ï¼‰ãªã‚‰æç”»ã›ãšã«æ¡ˆå†…ã—ã¦çµ‚äº†
    if piv.shape[1] == 0:
        st.info("è¡¨ç¤ºå¯¾è±¡ãŒã‚ã‚Šã¾ã›ã‚“ã€‚å·¦ã®ãƒªã‚¹ãƒˆã‹ã‚‰1ã¤ä»¥ä¸Šé¸ã‚“ã§ãã ã•ã„ã€‚")
        return

    if ma > 1:
        piv = piv.rolling(window=int(ma), min_periods=1).mean()

    # â˜… ä¸€æ„ã‚­ãƒ¼ï¼šå¹´ç¯„å›²ãƒ»ãƒ¢ãƒ¼ãƒ‰ãƒ»é¸æŠãƒ»MAã§ãƒ¦ãƒ‹ãƒ¼ã‚¯åŒ–
    _sel_key = ",".join(sel) if sel else "__ALL__"
    _uniq_key = f"obj_trend_plot|{y_from}-{y_to}|{target_mode}|{_sel_key}|ma{ma}"

    if HAS_PX:
        fig = px.line(
            piv.reset_index().melt(id_vars="ç™ºè¡Œå¹´", var_name="é …ç›®", value_name="ä»¶æ•°"),
            x="ç™ºè¡Œå¹´", y="ä»¶æ•°", color="é …ç›®", markers=True
        )
        fig.update_layout(height=520, margin=dict(l=10,r=10,t=30,b=10))
        # â˜… key ã‚’ä»˜ã‘ã¦é‡è¤‡IDå›é¿ï¼ˆæ—§ç‰ˆã§ã‚‚ key ã¯åˆ©ç”¨å¯èƒ½ï¼‰
        st.plotly_chart(fig, use_container_width=True, key=_uniq_key)
    else:
        # st.line_chart ã‚‚ key ã‚’ä»˜ã‘ã¦ãŠãã¨å®‰å¿ƒ
        st.line_chart(piv, key=_uniq_key)


# ========= â‘¢ å…±èµ·ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ =========
def _build_cooccur_edges(df: pd.DataFrame,
                         mode: str,
                         min_edge: int) -> pd.DataFrame:
    """
    mode: 'å¯¾è±¡ç‰©ã®ã¿' | 'ç ”ç©¶ã‚¿ã‚¤ãƒ—ã®ã¿' | 'å¯¾è±¡ç‰©Ã—ç ”ç©¶ã‚¿ã‚¤ãƒ—'
    æˆ»ã‚Šå€¤: ['src','dst','weight']
    """
    rows: List[Tuple[str, str]] = []
    for _, r in df.iterrows():
        tg = list(dict.fromkeys(split_multi(r.get("å¯¾è±¡ç‰©_top3", ""))))
        tp = list(dict.fromkeys(split_multi(r.get("ç ”ç©¶ã‚¿ã‚¤ãƒ—_top3", ""))))
        if mode == "å¯¾è±¡ç‰©ã®ã¿":
            items = tg
            pairs = itertools.combinations(sorted(items), 2)
        elif mode == "ç ”ç©¶ã‚¿ã‚¤ãƒ—ã®ã¿":
            items = tp
            pairs = itertools.combinations(sorted(items), 2)
        else:  # å¯¾è±¡ç‰©Ã—ç ”ç©¶ã‚¿ã‚¤ãƒ—ï¼ˆåŒéƒ¨ï¼‰
            pairs = itertools.product(sorted(set(tg)), sorted(set(tp)))
        for a, b in pairs:
            if a and b and a != b:
                rows.append((a, b))
    if not rows:
        return pd.DataFrame(columns=["src", "dst", "weight"])
    edges = pd.DataFrame(rows, columns=["src", "dst"]).value_counts().reset_index(name="weight")
    edges = edges[edges["weight"] >= int(min_edge)].sort_values("weight", ascending=False).reset_index(drop=True)
    return edges

def _draw_pyvis_from_edges(edges: pd.DataFrame, height_px: int = 650) -> None:
    if not (HAS_NX and HAS_PYVIS):
        st.info("ã‚°ãƒ©ãƒ•æç”»ã«ã¯ networkx / pyvis ãŒå¿…è¦ã§ã™ã€‚")
        return
    if edges.empty:
        st.warning("ã‚¨ãƒƒã‚¸ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    # NX Graph
    G = nx.Graph()
    for _, r in edges.iterrows():
        s, t, w = r["src"], r["dst"], int(r["weight"])
        if G.has_edge(s, t):
            G[s][t]["weight"] += w
        else:
            G.add_edge(s, t, weight=w)

    # PyVis
    net = Network(height=f"{height_px}px", width="100%", bgcolor="#ffffff", font_color="#222")
    net.barnes_hut(gravity=-30000, central_gravity=0.25, spring_length=120, spring_strength=0.02)
    net.from_nx(G)
    # ç”Ÿæˆâ†’åŸ‹ã‚è¾¼ã¿ï¼ˆopen_browserã‚’ä½¿ã‚ãªã„ï¼‰
    html = net.generate_html(notebook=False)
    st.components.v1.html(html, height=height_px, scrolling=True)

def _render_cooccurrence_block(df: pd.DataFrame) -> None:
    st.markdown("### â‘¢ å…±èµ·ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆå¯¾è±¡ç‰©ãƒ»ç ”ç©¶ã‚¿ã‚¤ãƒ—ï¼‰")

    ymin_all, ymax_all = _year_min_max(df)
    c1, c2, c3, c4 = st.columns([1, 1, 1, 1])
    with c1:
        y_from, y_to = st.slider("å¯¾è±¡å¹´ï¼ˆç¯„å›²ï¼‰", min_value=ymin_all, max_value=ymax_all, value=(ymin_all, ymax_all), key="obj_net_year")
    with c2:
        mode = st.selectbox("ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ç¨®é¡", ["å¯¾è±¡ç‰©ã®ã¿", "ç ”ç©¶ã‚¿ã‚¤ãƒ—ã®ã¿", "å¯¾è±¡ç‰©Ã—ç ”ç©¶ã‚¿ã‚¤ãƒ—"], index=0, key="obj_net_mode")
    with c3:
        min_edge = st.number_input("ã‚¨ãƒƒã‚¸æœ€å°å›æ•° (wâ‰¥)", min_value=1, max_value=50, value=3, step=1, key="obj_net_minw")
    with c4:
        topN = st.number_input("ä¸Šä½ã®ãƒãƒ¼ãƒ‰æ•°ï¼ˆä¸Šé™ï¼‰", min_value=30, max_value=300, value=120, step=10, key="obj_net_topn")

    # å¹´ã ã‘å½“ã¦ãŸãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å€™è£œã‚’æŠ½å‡º
    use_year = _apply_filters(df, y_from, y_to, [], [])
    tg_all = sorted({t for v in use_year.get("å¯¾è±¡ç‰©_top3", pd.Series(dtype=str)).fillna("")
                    for t in split_multi(v)})
    tp_all = sorted({t for v in use_year.get("ç ”ç©¶ã‚¿ã‚¤ãƒ—_top3", pd.Series(dtype=str)).fillna("")
                    for t in split_multi(v)})

    # â˜… è¡¨ç¤ºé †ã‚’å›ºå®š
    tg_all = _order_options(tg_all, TARGET_ORDER)
    tp_all = _order_options(tp_all, TYPE_ORDER)

    c5, c6 = st.columns([1, 1])
    with c5:
        tg_needles = st.multiselect("å¯¾è±¡ç‰©ã§çµã‚Šè¾¼ã¿ï¼ˆé¸æŠï¼‰", tg_all, default=[], key="obj_net_tg_sel")
    with c6:
        tp_needles = st.multiselect("ç ”ç©¶ã‚¿ã‚¤ãƒ—ã§çµã‚Šè¾¼ã¿ï¼ˆé¸æŠï¼‰", tp_all, default=[], key="obj_net_tp_sel")

    use = _apply_filters(df, y_from, y_to, tg_needles, tp_needles)

    # ---- ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ ----
    cache_key = f"objnet|{y_from}-{y_to}|{mode}|min{min_edge}|top{topN}|tg{','.join(tg_needles)}|tp{','.join(tp_needles)}"

    # 1) ã‚¨ãƒƒã‚¸æ§‹ç¯‰ï¼ˆé‡ã„ã®ã§æ°¸ç¶šã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼‰
    edges = None
    if HAS_DISK_CACHE:
        path_edges = cache_csv_path("obj_net_edges", cache_key)
        cached = load_csv_if_exists(path_edges)
        if cached is not None:
            edges = cached

    if edges is None:
        edges = _build_cooccur_edges(use, mode, int(min_edge))
        # ä¸Šä½ãƒãƒ¼ãƒ‰åˆ¶é™ï¼šå‡ºç¾å¤šã„ãƒãƒ¼ãƒ‰ã‚’æ®‹ã™
        if not edges.empty and int(topN) > 0:
            deg = pd.concat([edges.groupby("src")["weight"].sum(),
                             edges.groupby("dst")["weight"].sum()], axis=1).fillna(0).sum(axis=1)
            keep_nodes = set(deg.sort_values(ascending=False).head(int(topN)).index.tolist())
            edges = edges[edges["src"].isin(keep_nodes) & edges["dst"].isin(keep_nodes)].reset_index(drop=True)
        if HAS_DISK_CACHE:
            save_csv(edges, path_edges)

    st.caption(f"ã‚¨ãƒƒã‚¸æ•°: {len(edges)}")
    st.dataframe(edges.head(200), use_container_width=True, hide_index=True)

    # 2) ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æç”»
    with st.expander("ğŸ•¸ï¸ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’æç”»ï¼ˆPyVis / ä»»æ„ä¾å­˜ï¼‰", expanded=False):
        if HAS_PYVIS and HAS_NX:
            if st.button("ğŸŒ æç”»ã™ã‚‹", key="obj_net_draw"):
                _draw_pyvis_from_edges(edges, height_px=680)
        else:
            st.info("networkx / pyvis ãŒæœªå°å…¥ã®ãŸã‚ã€è¡¨ã®ã¿è¡¨ç¤ºã—ã¦ã„ã¾ã™ã€‚")


# ========= ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆï¼šã‚¿ãƒ–æœ¬ä½“ =========
def render_targettype_tab(df: pd.DataFrame) -> None:
    st.markdown("## ğŸ§‚ å¯¾è±¡ç‰©ãƒ»ç ”ç©¶ã‚¿ã‚¤ãƒ—åˆ†æ")

    tab1, tab2, tab3 = st.tabs([
        "â‘  æ§‹æˆæ¯”ãƒ»ã‚¯ãƒ­ã‚¹é›†è¨ˆ",
        "â‘¡ çµŒå¹´å¤‰åŒ–",
        "â‘¢ å…±èµ·ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯",
    ])

    with tab1:
        _render_distribution_block(df)
        st.divider()
        _render_cross_block(df)   # â† è¿½åŠ 

    with tab2:
        _render_trend_block(df)

    with tab3:
        _render_cooccurrence_block(df)