# modules/analysis/coauthor.py
# -*- coding: utf-8 -*-
"""
å…±è‘—ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆç ”ç©¶è€…ã®ã¤ãªãŒã‚Šãƒ©ãƒ³ã‚­ãƒ³ã‚° + ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å¯è¦–åŒ–ï¼‰
- å¹´/å¯¾è±¡ç‰©/ç ”ç©¶ã‚¿ã‚¤ãƒ—ã§ãƒ•ã‚£ãƒ«ã‚¿
- è¡¨: è‘—è€… / å…±è‘—æ•° / ã¤ãªãŒã‚Šã‚¹ã‚³ã‚¢ï¼ˆä¸­å¿ƒæ€§ï¼‰ ã®3åˆ—
- ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æç”»ã¯ PyVisï¼ˆgenerate_html ã§å®‰å®šåŸ‹ã‚è¾¼ã¿ï¼‰
- ãƒ‡ã‚£ã‚¹ã‚¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥å¯¾å¿œï¼ˆ.cacheé…ä¸‹ï¼‰
"""

from __future__ import annotations
import re
import itertools
from pathlib import Path
import pandas as pd
import streamlit as st

# --- Optional deps ---
try:
    import networkx as nx
    HAS_NX = True
except Exception:
    HAS_NX = False

try:
    from pyvis.network import Network
    HAS_PYVIS = True
except Exception:
    HAS_PYVIS = False

# å…±æœ‰ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆç°¡æ˜“ï¼‰
_AUTHOR_SPLIT_RE = re.compile(r"[;ï¼›,ã€ï¼Œ/ï¼|ï½œ]+")
def split_authors(cell):
    if cell is None: return []
    return [w.strip() for w in _AUTHOR_SPLIT_RE.split(str(cell)) if w.strip()]

def split_multi(s):
    if not s: return []
    return [w.strip() for w in re.split(r"[;ï¼›,ã€ï¼Œ/ï¼|ï½œ\sã€€]+", str(s)) if w.strip()]

# ---- ãƒ‡ã‚£ã‚¹ã‚¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆå…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£æœ€å°ç‰ˆï¼‰ ----
CACHE_DIR = Path(".cache"); CACHE_DIR.mkdir(exist_ok=True)
def _sig(*parts) -> str:
    import hashlib
    h = hashlib.md5()
    for p in parts:
        h.update(str(p).encode("utf-8"))
    return h.hexdigest()
def _cache_csv(prefix: str, *params) -> Path:
    return CACHE_DIR / f"{prefix}_{_sig(*params)}.csv"
def _load_csv(p: Path) -> pd.DataFrame | None:
    if p.exists():
        try: return pd.read_csv(p)
        except Exception: return None
    return None
def _save_csv(df: pd.DataFrame, p: Path):
    try: df.to_csv(p, index=False)
    except Exception: pass

# ========= ã‚¨ãƒƒã‚¸ç”Ÿæˆ =========
@st.cache_data(ttl=600, show_spinner=False)
def build_coauthor_edges(df: pd.DataFrame) -> pd.DataFrame:
    """dfï¼ˆè‘—è€…åˆ—ã¯ãƒ•ã‚£ãƒ«ã‚¿æ¸ˆã¿ã®ã‚‚ã®ï¼‰â†’ edges[src,dst,weight]"""
    if df is None or "è‘—è€…" not in df.columns:
        return pd.DataFrame(columns=["src", "dst", "weight"])

    rows = []
    for authors in df["è‘—è€…"].fillna(""):
        names = split_authors(authors)
        uniq = sorted(set(names))
        for s, t in itertools.combinations(uniq, 2):
            rows.append((s, t))

    if not rows:
        return pd.DataFrame(columns=["src", "dst", "weight"])

    edges = pd.DataFrame(rows, columns=["src", "dst"])
    # ç„¡å‘ã‚°ãƒ©ãƒ•ãªã®ã§ pair ã‚’ã‚½ãƒ¼ãƒˆã—ã¦é›†è¨ˆ
    edges["pair"] = edges.apply(lambda r: tuple(sorted([r["src"], r["dst"]])), axis=1)
    edges = edges.groupby("pair").size().reset_index(name="weight")
    edges[["src", "dst"]] = pd.DataFrame(edges["pair"].tolist(), index=edges.index)
    edges = edges.drop(columns=["pair"]).sort_values("weight", ascending=False).reset_index(drop=True)
    return edges[["src", "dst", "weight"]]

def _apply_filters(df: pd.DataFrame,
                   year_from: int | None, year_to: int | None,
                   targets_sel: list[str] | None, types_sel: list[str] | None) -> pd.DataFrame:
    use = df.copy()
    if "ç™ºè¡Œå¹´" in use.columns and year_from is not None and year_to is not None:
        y = pd.to_numeric(use["ç™ºè¡Œå¹´"], errors="coerce")
        use = use[(y >= year_from) & (y <= year_to) | y.isna()]

    if targets_sel and "å¯¾è±¡ç‰©_top3" in use.columns:
        keys = [k.lower() for k in targets_sel]
        use = use[use["å¯¾è±¡ç‰©_top3"].astype(str).str.lower().apply(lambda v: any(k in v for k in keys))]

    if types_sel and "ç ”ç©¶ã‚¿ã‚¤ãƒ—_top3" in use.columns:
        keys = [k.lower() for k in types_sel]
        use = use[use["ç ”ç©¶ã‚¿ã‚¤ãƒ—_top3"].astype(str).str.lower().apply(lambda v: any(k in v for k in keys))]

    return use

def get_coauthor_edges(df: pd.DataFrame,
                       year_from: int | None, year_to: int | None,
                       targets_sel: list[str] | None,
                       types_sel: list[str] | None,
                       use_disk_cache: bool) -> pd.DataFrame:
    """ãƒ•ã‚£ãƒ«ã‚¿è¾¼ã¿ã§ã‚¨ãƒƒã‚¸ä½œæˆï¼‹CSVã‚­ãƒ£ãƒƒã‚·ãƒ¥"""
    use = _apply_filters(df, year_from, year_to, targets_sel, types_sel)
    keypath = _cache_csv("coauthor_edges",
                         len(use), year_from, year_to,
                         ",".join(sorted(targets_sel or [])),
                         ",".join(sorted(types_sel or [])))
    if use_disk_cache:
        cached = _load_csv(keypath)
        if cached is not None: return cached

    edges = build_coauthor_edges(use)
    if use_disk_cache and not edges.empty:
        _save_csv(edges, keypath)
    return edges

# ========= ä¸­å¿ƒæ€§ =========
def _centrality_from_edges(edges: pd.DataFrame, metric: str = "degree") -> pd.DataFrame:
    """
    input: edges[src,dst,weight]
    output: DataFrame['è‘—è€…','å…±è‘—æ•°','ã¤ãªãŒã‚Šã‚¹ã‚³ã‚¢']
    - å…±è‘—æ•°: æ¥ç¶šã‚¨ãƒƒã‚¸é‡ã¿ã®åˆè¨ˆï¼ˆç°¡æ˜“ãªâ€œé–¢ä¸åº¦â€ï¼‰
    - ã¤ãªãŒã‚Šã‚¹ã‚³ã‚¢: degree/betweenness/eigenvector (networkxç„¡ã„å ´åˆã¯å…±è‘—æ•°ã‚’ãã®ã¾ã¾)
    """
    if edges.empty:
        return pd.DataFrame(columns=["è‘—è€…", "å…±è‘—æ•°", "ã¤ãªãŒã‚Šã‚¹ã‚³ã‚¢"])

    # å…±è‘—æ•°ï¼ˆé‡ã¿åˆè¨ˆï¼‰
    deg = pd.concat([
        edges.groupby("src")["weight"].sum(),
        edges.groupby("dst")["weight"].sum(),
    ], axis=1).fillna(0)
    deg["å…±è‘—æ•°"] = deg["weight"].sum(axis=1)
    deg = deg[["å…±è‘—æ•°"]]

    if not HAS_NX:
        out = deg.sort_values("å…±è‘—æ•°", ascending=False).reset_index().rename(columns={"index": "è‘—è€…"})
        out["ã¤ãªãŒã‚Šã‚¹ã‚³ã‚¢"] = out["å…±è‘—æ•°"]  # ä»£æ›¿
        return out

    # networkx ã§ä¸­å¿ƒæ€§
    G = nx.Graph()
    for _, r in edges.iterrows():
        s, t, w = r["src"], r["dst"], float(r["weight"])
        if G.has_edge(s, t):
            G[s][t]["weight"] += w
        else:
            G.add_edge(s, t, weight=w)

    if metric == "betweenness":
        cen = nx.betweenness_centrality(G, weight="weight", normalized=True)
    elif metric == "eigenvector":
        try:
            cen = nx.eigenvector_centrality_numpy(G, weight="weight")
        except Exception:
            cen = nx.degree_centrality(G)
    else:
        cen = nx.degree_centrality(G)

    cen = pd.Series(cen, name="ã¤ãªãŒã‚Šã‚¹ã‚³ã‚¢")
    out = deg.join(cen, how="outer").fillna(0).reset_index().rename(columns={"index": "è‘—è€…"})
    out = out.sort_values(["ã¤ãªãŒã‚Šã‚¹ã‚³ã‚¢", "å…±è‘—æ•°"], ascending=False).reset_index(drop=True)
    return out

# ========= å¯è¦–åŒ– =========
def _draw_network(edges: pd.DataFrame, top_nodes=None, min_weight=1, height_px=650):
    """PyVisã§å®‰å®šåŸ‹ã‚è¾¼ã¿ï¼ˆgenerate_htmlä½¿ç”¨ï¼‰"""
    if not (HAS_NX and HAS_PYVIS):
        st.info("âš ï¸ ã‚°ãƒ©ãƒ•æç”»ã«ã¯ networkx / pyvis ãŒå¿…è¦ã§ã™ã€‚ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨ã¯åˆ©ç”¨ã§ãã¾ã™ã€‚")
        return
    edges_use = edges[edges["weight"] >= int(min_weight)]
    if edges_use.empty:
        st.warning("æ¡ä»¶ã«åˆã†å…±è‘—é–¢ä¿‚ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        return

    G = nx.Graph()
    for _, r in edges_use.iterrows():
        G.add_edge(r["src"], r["dst"], weight=int(r["weight"]))

    if top_nodes:
        # â€œå­˜åœ¨ã—ãªã„ãƒãƒ¼ãƒ‰â€ã‚’å¼¾ã
        top_nodes = [n for n in (top_nodes or []) if n in G]
        keep = set(top_nodes) | {nbr for n in top_nodes for nbr in G.neighbors(n)}
        G = G.subgraph(keep).copy()
        if len(G) == 0:
            st.warning("ãƒˆãƒƒãƒ—è¿‘å‚ã«ã‚¨ãƒƒã‚¸ãŒã‚ã‚Šã¾ã›ã‚“ã€‚é–¾å€¤ã‚’ä¸‹ã’ã¦ãã ã•ã„ã€‚")
            return

    net = Network(height=f"{height_px}px", width="100%", bgcolor="#fff", font_color="#222")
    net.barnes_hut(gravity=-25000, central_gravity=0.25, spring_length=110, spring_strength=0.02)
    for n in G.nodes():
        net.add_node(n, label=n)
    for s, t, d in G.edges(data=True):
        w = int(d.get("weight", 1))
        net.add_edge(s, t, value=w, title=f"å…±è‘—å›æ•°: {w}")

    net.set_options('{"nodes":{"shape":"dot","scaling":{"min":10,"max":40}},"edges":{"smooth":false}}')

    # â˜… ãƒ–ãƒ©ã‚¦ã‚¶è‡ªå‹•ã‚ªãƒ¼ãƒ—ãƒ³ã‚’å›é¿ã—ã¦HTMLæ–‡å­—åˆ—ã‚’ç›´æ¥åŸ‹ã‚è¾¼ã‚€
    html = net.generate_html(notebook=False)
    st.components.v1.html(html, height=height_px, scrolling=True)

# ========= UI =========
def render_coauthor_tab(df: pd.DataFrame, use_disk_cache: bool = False):
    st.markdown("## ğŸ‘¥ ç ”ç©¶è€…ã®ã¤ãªãŒã‚Šåˆ†æï¼ˆå…±è‘—ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼‰")

    # å¹´ç¯„å›²
    if "ç™ºè¡Œå¹´" in df.columns:
        y = pd.to_numeric(df["ç™ºè¡Œå¹´"], errors="coerce")
        if y.notna().any():
            ymin, ymax = int(y.min()), int(y.max())
        else:
            ymin, ymax = 1980, 2025
    else:
        ymin, ymax = 1980, 2025

    # ãƒ•ã‚£ãƒ«ã‚¿UIï¼ˆã‚­ãƒ¼è¡çªå›é¿ã®ãŸã‚æ¥é ­è¾ï¼‰
    kpref = "co_"
    c1, c2, c3, c4 = st.columns([1, 1, 1, 1])
    with c1:
        y_from, y_to = st.slider("å¯¾è±¡å¹´ï¼ˆç¯„å›²ï¼‰", min_value=ymin, max_value=ymax, value=(ymin, ymax), key=f"{kpref}yr")
    with c2:
        metric = st.selectbox("ã‚¹ã‚³ã‚¢è¨ˆç®—æ–¹å¼", ["degree", "betweenness", "eigenvector"], index=0, key=f"{kpref}met")
    with c3:
        top_n = st.number_input("ãƒ©ãƒ³ã‚­ãƒ³ã‚°ä»¶æ•°", min_value=5, max_value=100, value=30, step=5, key=f"{kpref}n")
    with c4:
        min_w = st.number_input("å…±è‘—å›æ•°ã®ä¸‹é™ (wâ‰¥)", min_value=1, max_value=20, value=2, step=1, key=f"{kpref}mw")

    # å¯¾è±¡ç‰©/ç ”ç©¶ã‚¿ã‚¤ãƒ—ï¼ˆå€™è£œæŠ½å‡ºã¯ã‚·ãƒ³ãƒ—ãƒ«ã«ï¼‰
    c5, c6 = st.columns([1, 1])
    with c5:
        targets_all = sorted({t for v in df.get("å¯¾è±¡ç‰©_top3", pd.Series(dtype=str)).fillna("") for t in split_multi(v)})
        targets_sel = st.multiselect("å¯¾è±¡ç‰©ï¼ˆéƒ¨åˆ†ä¸€è‡´ï¼‰", targets_all, default=[], key=f"{kpref}tg")
    with c6:
        types_all = sorted({t for v in df.get("ç ”ç©¶ã‚¿ã‚¤ãƒ—_top3", pd.Series(dtype=str)).fillna("") for t in split_multi(v)})
        types_sel = st.multiselect("ç ”ç©¶ã‚¿ã‚¤ãƒ—ï¼ˆéƒ¨åˆ†ä¸€è‡´ï¼‰", types_all, default=[], key=f"{kpref}tp")

    # ã‚¨ãƒƒã‚¸ä½œæˆï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥è€ƒæ…®ï¼‰
    edges = get_coauthor_edges(df, y_from, y_to, targets_sel, types_sel, use_disk_cache=use_disk_cache)
    if edges.empty:
        st.info("å…±è‘—é–¢ä¿‚ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚æ¡ä»¶ã‚’ç·©ã‚ã¦ãŠè©¦ã—ãã ã•ã„ã€‚")
        return

    # ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆè‘—è€… / å…±è‘—æ•° / ã¤ãªãŒã‚Šã‚¹ã‚³ã‚¢ï¼‰
    st.markdown("### ğŸ” ç ”ç©¶è€…ã®ã¤ãªãŒã‚Šãƒ©ãƒ³ã‚­ãƒ³ã‚°")
    rank = _centrality_from_edges(edges, metric=metric).head(int(top_n))
    st.dataframe(rank[["è‘—è€…", "å…±è‘—æ•°", "ã¤ãªãŒã‚Šã‚¹ã‚³ã‚¢"]], use_container_width=True, hide_index=True)

    # å¯è¦–åŒ–
    with st.expander("ğŸ•¸ï¸ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’å¯è¦–åŒ–ï¼ˆä»»æ„ï¼‰", expanded=False):
        st.caption("PyVisã§ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ã«è¡¨ç¤ºã—ã¾ã™ï¼ˆnetworkx/pyvis ãŒå¿…è¦ï¼‰")
        top_only = st.toggle("ãƒˆãƒƒãƒ—Nã®å‘¨è¾ºã®ã¿è¡¨ç¤ºï¼ˆè»½é‡ï¼‰", value=True, key=f"{kpref}toponly")
        top_nodes = rank["è‘—è€…"].tolist() if top_only else None
        if st.button("ğŸŒ æç”»ã™ã‚‹", key=f"{kpref}draw"):
            _draw_network(edges, top_nodes=top_nodes, min_weight=int(min_w), height_px=700)