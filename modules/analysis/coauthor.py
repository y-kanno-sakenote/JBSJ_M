# modules/analysis/coauthor.py
# -*- coding: utf-8 -*-
"""
å…±è‘—ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆç ”ç©¶è€…ã®ã¤ãªãŒã‚Šãƒ©ãƒ³ã‚­ãƒ³ã‚° + ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å¯è¦–åŒ–ï¼‰
- ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨ã«ã€Œå…±è‘—æ•°ã€ã‚’è¿½åŠ 
- ä¸­å¿ƒæ€§ã‚¹ã‚³ã‚¢ã®æ£’ã‚°ãƒ©ãƒ• + ç°¡æ˜“ã‚³ãƒ¡ãƒ³ãƒˆã‚’è¡¨ç¤º
"""

import re
import itertools
import pandas as pd
import streamlit as st

# --- Optional deps ---
try:
    import networkx as nx
    HAS_NX = True
except Exception:
    HAS_NX = False

try:
    from pyvis.network import Network
    HAS_PYVIS = True
except Exception:
    HAS_PYVIS = False

try:
    import altair as alt
    HAS_ALTAIR = True
except Exception:
    HAS_ALTAIR = False


# ========= åŸºæœ¬ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ =========
_AUTHOR_SPLIT_RE = re.compile(r"[;ï¼›,ã€ï¼Œ/ï¼|ï½œ]+")

def split_authors(cell):
    if cell is None:
        return []
    return [w.strip() for w in _AUTHOR_SPLIT_RE.split(str(cell)) if w.strip()]


@st.cache_data(ttl=600, show_spinner=False)
def build_coauthor_edges(df: pd.DataFrame,
                         year_from: int | None = None,
                         year_to: int | None = None,
                         targets_sel: list[str] | None = None,
                         types_sel: list[str] | None = None) -> pd.DataFrame:
    """è‘—è€…ãƒšã‚¢ã‚’æŠ½å‡ºã—ã¦å…±è‘—å›æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ"""
    if df is None or "è‘—è€…" not in df.columns:
        return pd.DataFrame(columns=["src", "dst", "weight"])

    use = df.copy()

    # ï¼ˆä»»æ„ï¼‰å¯¾è±¡å¹´ã®çµã‚Šè¾¼ã¿
    if "ç™ºè¡Œå¹´" in use.columns and (year_from is not None and year_to is not None):
        y = pd.to_numeric(use["ç™ºè¡Œå¹´"], errors="coerce")
        use = use[(y >= year_from) & (y <= year_to) | y.isna()]

    # ï¼ˆä»»æ„ï¼‰å¯¾è±¡ç‰© / ç ”ç©¶ã‚¿ã‚¤ãƒ—ã®éƒ¨åˆ†ä¸€è‡´ãƒ•ã‚£ãƒ«ã‚¿
    def _norm(s: str) -> str:
        return re.sub(r"\s+", " ", str(s or "")).strip().lower()

    if targets_sel and "å¯¾è±¡ç‰©_top3" in use.columns:
        keys = [_norm(t) for t in targets_sel]
        use = use[use["å¯¾è±¡ç‰©_top3"].astype(str).str.lower().apply(lambda v: any(k in v for k in keys))]

    if types_sel and "ç ”ç©¶ã‚¿ã‚¤ãƒ—_top3" in use.columns:
        keys = [_norm(t) for t in types_sel]
        use = use[use["ç ”ç©¶ã‚¿ã‚¤ãƒ—_top3"].astype(str).str.lower().apply(lambda v: any(k in v for k in keys))]

    rows = []
    for authors in use["è‘—è€…"].fillna(""):
        names = split_authors(authors)
        for s, t in itertools.combinations(sorted(set(names)), 2):
            rows.append((s, t))

    if not rows:
        return pd.DataFrame(columns=["src", "dst", "weight"])

    edges = pd.DataFrame(rows, columns=["src", "dst"])
    edges["pair"] = edges.apply(lambda r: tuple(sorted([r["src"], r["dst"]])), axis=1)
    edges = edges.groupby("pair").size().reset_index(name="weight")
    edges[["src", "dst"]] = pd.DataFrame(edges["pair"].tolist(), index=edges.index)
    edges = edges.drop(columns=["pair"]).sort_values("weight", ascending=False).reset_index(drop=True)
    return edges


def _author_coauthor_counts(edges: pd.DataFrame) -> pd.DataFrame:
    """ãƒãƒ¼ãƒ‰ã”ã¨ã®å…±è‘—æ•°ï¼ˆé‡ã¿åˆè¨ˆï¼‰= é‡ã¿ä»˜ãæ¬¡æ•°"""
    if edges.empty:
        return pd.DataFrame(columns=["è‘—è€…", "å…±è‘—æ•°"])
    left = edges.groupby("src")["weight"].sum()
    right = edges.groupby("dst")["weight"].sum()
    deg = pd.concat([left, right], axis=1).fillna(0)
    deg["å…±è‘—æ•°"] = deg.sum(axis=1).astype(int)
    out = deg["å…±è‘—æ•°"].reset_index().rename(columns={"index": "è‘—è€…"})
    return out


def _centrality_from_edges(edges: pd.DataFrame, metric: str = "degree") -> pd.DataFrame:
    """ä¸­å¿ƒæ€§ã‚¹ã‚³ã‚¢ã‚’ç®—å‡ºã—ã€å…±è‘—æ•°ã¨ãƒãƒ¼ã‚¸ã—ã¦è¿”ã™"""
    counts = _author_coauthor_counts(edges)  # è‘—è€…, å…±è‘—æ•°

    # networkxç„¡ã—ï¼šç°¡æ˜“ã‚¹ã‚³ã‚¢ï¼ˆå…±è‘—æ•°ã‚’ãã®ã¾ã¾ã‚¹ã‚³ã‚¢æ‰±ã„ï¼‰
    if not HAS_NX:
        out = counts.copy()
        out["ã¤ãªãŒã‚Šã‚¹ã‚³ã‚¢"] = out["å…±è‘—æ•°"].astype(float)
        out["note"] = "networkxæœªå°å…¥: å…±è‘—æ•°=ã‚¹ã‚³ã‚¢"
        out = out.sort_values("ã¤ãªãŒã‚Šã‚¹ã‚³ã‚¢", ascending=False).reset_index(drop=True)
        return out[["è‘—è€…", "å…±è‘—æ•°", "ã¤ãªãŒã‚Šã‚¹ã‚³ã‚¢", "note"]]

    # networkxã‚ã‚Š
    G = nx.Graph()
    for _, r in edges.iterrows():
        s, t, w = r["src"], r["dst"], float(r["weight"])
        if G.has_edge(s, t):
            G[s][t]["weight"] += w
        else:
            G.add_edge(s, t, weight=w)

    if metric == "betweenness":
        cen = nx.betweenness_centrality(G, weight="weight", normalized=True)
    elif metric == "eigenvector":
        try:
            cen = nx.eigenvector_centrality_numpy(G, weight="weight")
        except Exception:
            cen = nx.degree_centrality(G)
    else:
        cen = nx.degree_centrality(G)

    cen_df = (pd.Series(cen, name="ã¤ãªãŒã‚Šã‚¹ã‚³ã‚¢")
                .reset_index()
                .rename(columns={"index": "è‘—è€…"}))

    out = cen_df.merge(counts, on="è‘—è€…", how="left")
    out["note"] = f"{metric}ä¸­å¿ƒæ€§"
    out = out.sort_values("ã¤ãªãŒã‚Šã‚¹ã‚³ã‚¢", ascending=False).reset_index(drop=True)
    return out[["è‘—è€…", "å…±è‘—æ•°", "ã¤ãªãŒã‚Šã‚¹ã‚³ã‚¢", "note"]]


def _draw_network(edges: pd.DataFrame, top_nodes=None, min_weight=1, height_px=650):
    """å…±è‘—ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’PyVisã§æç”»"""
    if not (HAS_NX and HAS_PYVIS):
        st.info("âš ï¸ ã‚°ãƒ©ãƒ•æç”»ã«ã¯ networkx / pyvis ãŒå¿…è¦ã§ã™ã€‚ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨ã¯åˆ©ç”¨ã§ãã¾ã™ã€‚")
        return

    edges_use = edges[edges["weight"] >= min_weight]
    if edges_use.empty:
        st.warning("æ¡ä»¶ã«åˆã†å…±è‘—é–¢ä¿‚ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        return

    G = nx.Graph()
    for _, r in edges_use.iterrows():
        G.add_edge(r["src"], r["dst"], weight=int(r["weight"]))

    if top_nodes:
        # ã‚°ãƒ©ãƒ•ã«å­˜åœ¨ã™ã‚‹ãƒãƒ¼ãƒ‰ã ã‘ä½¿ã†ï¼ˆå­˜åœ¨ã—ãªã„ãƒãƒ¼ãƒ‰ã§è½ã¡ãªã„ã‚ˆã†ã«ï¼‰
        existing = [n for n in (top_nodes or []) if n in G]
        keep = set(existing) | {nbr for n in existing for nbr in G.neighbors(n)}
        G = G.subgraph(keep).copy()

    net = Network(height=f"{height_px}px", width="100%", bgcolor="#fff", font_color="#222")
    net.barnes_hut(gravity=-30000, central_gravity=0.25, spring_length=110)
    for n in G.nodes():
        net.add_node(n, label=n)
    for s, t, d in G.edges(data=True):
        w = int(d.get("weight", 1))
        net.add_edge(s, t, value=w, title=f"å…±è‘—å›æ•°: {w}")

    # ç›´æ¥åŸ‹ã‚è¾¼ã¿ï¼ˆpyvisã®ãƒ–ãƒ©ã‚¦ã‚¶èµ·å‹•ã‚’å›é¿ï¼‰
    html = net.generate_html(notebook=False)
    st.components.v1.html(html, height=height_px, scrolling=True)


# ========= UIæ§‹ç¯‰ =========
def render_coauthor_tab(df: pd.DataFrame):
    st.markdown("## ğŸ‘¥ ç ”ç©¶è€…ã®ã¤ãªãŒã‚Šåˆ†æï¼ˆå…±è‘—ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼‰")
    st.caption("å…±è‘—ãŒå¤šã„ãƒ»å½±éŸ¿åŠ›ã®ã‚ã‚‹ç ”ç©¶è€…ã‚’è¦‹ã¤ã‘ã¾ã™ã€‚ã‚¹ã‚³ã‚¢ã¯ 'ä¸­å¿ƒæ€§'ï¼ˆdegree / betweenness / eigenvectorï¼‰ãŒé¸ã¹ã¾ã™ã€‚")

    if df is None or "è‘—è€…" not in df.columns:
        st.warning("è‘—è€…ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return

    # å¹´ç¯„å›²
    if "ç™ºè¡Œå¹´" in df.columns:
        y = pd.to_numeric(df["ç™ºè¡Œå¹´"], errors="coerce")
        if y.notna().any():
            ymin, ymax = int(y.min()), int(y.max())
        else:
            ymin, ymax = 1980, 2025
    else:
        ymin, ymax = 1980, 2025

    # ä¸Šæ®µï¼šãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã¨è¨ˆç®—æ¡ä»¶
    c1, c2 = st.columns([1.4, 1.6])
    with c1:
        year_from, year_to = st.slider("å¯¾è±¡å¹´", min_value=ymin, max_value=ymax, value=(ymin, ymax))
        metric = st.selectbox("ã‚¹ã‚³ã‚¢è¨ˆç®—æ–¹å¼", ["degree", "betweenness", "eigenvector"], index=0,
                              help="networkxæœªå°å…¥æ™‚ã¯ã€Œå…±è‘—æ•°=ã‚¹ã‚³ã‚¢ã€ã®ç°¡æ˜“è¨ˆç®—ã«ãªã‚Šã¾ã™ã€‚")
    with c2:
        # æ—¢å­˜DFã®åˆ—ã‹ã‚‰å€™è£œã‚’åé›†ï¼ˆéƒ¨åˆ†ä¸€è‡´ã§ä½¿ã†ï¼‰
        targets_all = sorted({t for v in df.get("å¯¾è±¡ç‰©_top3", pd.Series(dtype=str)).fillna("") for t in re.split(r"[;ï¼›,ã€ï¼Œ/ï¼|ï½œ\sã€€]+", str(v)) if t})
        types_all   = sorted({t for v in df.get("ç ”ç©¶ã‚¿ã‚¤ãƒ—_top3", pd.Series(dtype=str)).fillna("") for t in re.split(r"[;ï¼›,ã€ï¼Œ/ï¼|ï½œ\sã€€]+", str(v)) if t})
        targets_sel = st.multiselect("å¯¾è±¡ç‰©ï¼ˆéƒ¨åˆ†ä¸€è‡´ï¼‰", targets_all, default=[])
        types_sel   = st.multiselect("ç ”ç©¶ã‚¿ã‚¤ãƒ—ï¼ˆéƒ¨åˆ†ä¸€è‡´ï¼‰", types_all, default=[])

    # --- ã‚¨ãƒƒã‚¸ä½œæˆï¼ˆå¹´ãƒ»å¯¾è±¡ç‰©ãƒ»ç ”ç©¶ã‚¿ã‚¤ãƒ—ã®ãƒ•ã‚£ãƒ«ã‚¿ã‚’åæ˜ ï¼‰ ---
    edges = build_coauthor_edges(
        df, year_from=year_from, year_to=year_to,
        targets_sel=targets_sel, types_sel=types_sel
    )
    if edges.empty:
        st.info("å…±è‘—é–¢ä¿‚ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ãƒ•ã‚£ãƒ«ã‚¿ã‚’ç·©ã‚ã¦å†åº¦è©¦ã—ã¦ãã ã•ã„ã€‚")
        return

    # --- ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆå…±è‘—æ•°ã‚’å«ã‚€ï¼‰ ---
    st.markdown("### ğŸ” ç ”ç©¶è€…ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆå…±è‘—æ•° + ã‚¹ã‚³ã‚¢ï¼‰")
    rank = _centrality_from_edges(edges, metric=metric)
    top_n = st.number_input("è¡¨ç¤ºä»¶æ•°", min_value=5, max_value=100, value=30, step=5)
    rank_view = rank.head(int(top_n))
    st.dataframe(rank_view[["è‘—è€…", "å…±è‘—æ•°", "ã¤ãªãŒã‚Šã‚¹ã‚³ã‚¢"]], use_container_width=True, hide_index=True)

    # --- æ£’ã‚°ãƒ©ãƒ•ï¼ˆä¸­å¿ƒæ€§ã‚¹ã‚³ã‚¢ï¼‰ ---
    st.markdown("### ğŸ“Š ã‚¹ã‚³ã‚¢ã®æ£’ã‚°ãƒ©ãƒ•")
    if not rank_view.empty:
        chart_df = rank_view.copy()
        # è‘—è€…åãŒé•·ã„å ´åˆã«æ¨ªä¸¦ã³ãŒæ½°ã‚Œãªã„ã‚ˆã†ã«åºæ•°ä»˜ä¸
        chart_df["label"] = [f"{i+1}. {a}" for i, a in enumerate(chart_df["è‘—è€…"])]
        if HAS_ALTAIR:
            chart = (alt.Chart(chart_df)
                     .mark_bar()
                     .encode(
                         x=alt.X("ã¤ãªãŒã‚Šã‚¹ã‚³ã‚¢:Q", title="ä¸­å¿ƒæ€§ã‚¹ã‚³ã‚¢"),
                         y=alt.Y("label:N", sort="-x", title="è‘—è€…"),
                         tooltip=["è‘—è€…", "å…±è‘—æ•°", "ã¤ãªãŒã‚Šã‚¹ã‚³ã‚¢"]
                     )
                     .properties(height=26 * len(chart_df), width="container"))
            st.altair_chart(chart, use_container_width=True)
        else:
            # ç°¡æ˜“ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            show = chart_df.set_index("label")["ã¤ãªãŒã‚Šã‚¹ã‚³ã‚¢"]
            st.bar_chart(show)

        # --- ç°¡æ˜“ã‚¤ãƒ³ã‚µã‚¤ãƒˆï¼ˆè‡ªå‹•ã‚³ãƒ¡ãƒ³ãƒˆï¼‰ ---
        top_row = chart_df.iloc[0]
        med = float(chart_df["ã¤ãªãŒã‚Šã‚¹ã‚³ã‚¢"].median())
        dominance = "çªå‡º" if top_row["ã¤ãªãŒã‚Šã‚¹ã‚³ã‚¢"] >= 2.0 * max(med, 1e-12) else "åˆ†æ•£"
        hint = {
            "degree": "ï¼å…±è‘—ç›¸æ‰‹ã®å¤šã•ï¼ˆãƒãƒ–åº¦ï¼‰ã‚’è¡¨ã—ã¾ã™ã€‚",
            "betweenness": "ï¼ç ”ç©¶ã‚°ãƒ«ãƒ¼ãƒ—é–“ã®â€œæ©‹æ¸¡ã—å½¹â€åº¦åˆã„ã‚’è¡¨ã—ã¾ã™ã€‚",
            "eigenvector": "ï¼å½±éŸ¿åŠ›ã®é«˜ã„ç ”ç©¶è€…ã¨ç¹‹ãŒã‚‹ã»ã©é«˜ããªã‚Šã¾ã™ã€‚"
        }.get(metric, "")

        st.markdown(
            f"""
- æœ€ä¸Šä½: **{top_row['è‘—è€…']}**ï¼ˆå…±è‘—æ•°: {int(top_row['å…±è‘—æ•°'])}ï¼‰  
- ã‚¹ã‚³ã‚¢åˆ†å¸ƒ: **{dominance}å‚¾å‘**ï¼ˆä¸­å¤®å€¤ â‰ˆ {med:.3f}ï¼‰  
- é¸æŠã‚¹ã‚³ã‚¢ã®æ„å‘³: **{metric}** {hint}
            """.strip()
        )

    # --- ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å¯è¦–åŒ–ï¼ˆä»»æ„ï¼‰ ---
    with st.expander("ğŸ•¸ï¸ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’å¯è¦–åŒ–ï¼ˆä»»æ„ãƒ»ä¾å­˜ã‚ã‚Šï¼‰", expanded=False):
        st.caption("å…±è‘—é–¢ä¿‚ã‚’ãƒãƒƒãƒ—ä¸Šã«å¯è¦–åŒ–ã—ã¾ã™ï¼ˆä¾å­˜: networkx / pyvisï¼‰")
        min_w = st.number_input("è¡¨ç¤ºã™ã‚‹æœ€å°å…±è‘—å›æ•° (wâ‰¥)", min_value=1, max_value=20, value=2, step=1)
        top_only = st.toggle("ãƒ†ãƒ¼ãƒ–ãƒ«ä¸Šä½ã®å‘¨è¾ºã®ã¿è¡¨ç¤ºï¼ˆè»½é‡ï¼‰", value=True)
        top_nodes = rank_view["è‘—è€…"].tolist() if top_only else None
        if st.button("ğŸŒ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’æç”»ã™ã‚‹"):
            _draw_network(edges, min_weight=int(min_w), top_nodes=top_nodes, height_px=700)