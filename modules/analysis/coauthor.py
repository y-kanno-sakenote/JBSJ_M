# modules/analysis/coauthor.py
# -*- coding: utf-8 -*-
"""
å…±è‘—ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆç ”ç©¶è€…ã®ã¤ãªãŒã‚Šãƒ©ãƒ³ã‚­ãƒ³ã‚° + ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å¯è¦–åŒ–ï¼‰
- å¹´ãƒ»å¯¾è±¡ç‰©ãƒ»ç ”ç©¶ã‚¿ã‚¤ãƒ—ã§ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆé¸æŠå¼ï¼‰
- ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨ï¼šè‘—è€… / å…±è‘—æ•° / ã¤ãªãŒã‚Šã‚¹ã‚³ã‚¢ï¼ˆä¸­å¿ƒæ€§ï¼‰
- ä¸­å¿ƒæ€§æŒ‡æ¨™ã¯æ—¥æœ¬èªè¡¨è¨˜ã§çµ±ä¸€ï¼ˆæ¬¡æ•°ä¸­å¿ƒæ€§ / åª’ä»‹ä¸­å¿ƒæ€§ / å›ºæœ‰ãƒ™ã‚¯ãƒˆãƒ«ä¸­å¿ƒæ€§ï¼‰
- ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æç”»ã¯ã€Œãƒœã‚¿ãƒ³ã€æŠ¼ä¸‹æ™‚ã®ã¿ï¼ˆPyVis / networkx ãŒã‚ã‚Œã°ï¼‰
- PyVis åŸ‹ã‚è¾¼ã¿ã¯ generate_html() ã‚’ä½¿ç”¨ï¼ˆãƒ–ãƒ©ã‚¦ã‚¶è‡ªå‹•èµ·å‹•ã‚’å›é¿ï¼‰
- ã‚µãƒ–ã‚¿ãƒ–ã€Œâ³ çµŒå¹´å¤‰åŒ–ã€ã¯ coauthor_temporal.py ãŒå­˜åœ¨ã™ã‚‹å ´åˆã®ã¿è‡ªå‹•ã§è¡¨ç¤º
"""

from __future__ import annotations
import re
import itertools
from typing import List, Tuple

import pandas as pd
import streamlit as st

# ---- ã‚µãƒ–ã‚¿ãƒ–ï¼ˆçµŒå¹´å¤‰åŒ–ï¼‰ã®ç›¸å¯¾importï¼šå­˜åœ¨ã—ãªã„å ´åˆã‚‚è½ã¨ã•ãªã„ ----
try:
    from .coauthor_temporal import render_coauthor_temporal_subtab  # åŒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæƒ³å®š
    HAS_TEMPORAL = True
except Exception:
    HAS_TEMPORAL = False

# --- Optional deps ---
try:
    import networkx as nx  # type: ignore
    HAS_NX = True
except Exception:
    HAS_NX = False

try:
    from pyvis.network import Network  # type: ignore
    HAS_PYVIS = True
except Exception:
    HAS_PYVIS = False

# --- æ°¸ç¶šã‚­ãƒ£ãƒƒã‚·ãƒ¥IOï¼ˆã‚ã‚Œã°ä½¿ã†ãƒ»ç„¡ãã¦ã‚‚å‹•ãï¼‰ ---
try:
    from modules.common.cache_utils import cache_csv_path, load_csv_if_exists, save_csv
    HAS_DISK_CACHE = True
except Exception:
    HAS_DISK_CACHE = False


# ========= åŸºæœ¬ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ =========
_AUTHOR_SPLIT_RE = re.compile(r"[;ï¼›,ã€ï¼Œ/ï¼|ï½œ]+")
_SPLIT_MULTI_RE  = re.compile(r"[;ï¼›,ã€ï¼Œ/ï¼|ï½œ\sã€€]+")

def split_authors(cell) -> List[str]:
    if cell is None:
        return []
    return [w.strip() for w in _AUTHOR_SPLIT_RE.split(str(cell)) if w.strip()]

def split_multi(s) -> List[str]:
    if not s:
        return []
    return [w.strip() for w in _SPLIT_MULTI_RE.split(str(s)) if w.strip()]

def norm_key(s: str) -> str:
    s = str(s or "").replace("\u00A0", " ")
    s = re.sub(r"\s+", " ", s).strip()
    return s.lower()

def col_contains_any(df_col: pd.Series, needles: List[str]) -> pd.Series:
    """åˆ—ï¼ˆæ–‡å­—åˆ—ï¼‰ã« needles ã®ã„ãšã‚Œã‹ãŒéƒ¨åˆ†ä¸€è‡´ã™ã‚‹ã‹ï¼ˆå°æ–‡å­—ãƒ»å…¨è§’ç©ºç™½æ­£è¦åŒ–ï¼‰ã€‚"""
    if not needles:
        return pd.Series([True] * len(df_col), index=df_col.index)
    lo_needles = [norm_key(n) for n in needles]
    def _hit(v: str) -> bool:
        s = norm_key(v)
        return any(n in s for n in lo_needles)
    return df_col.fillna("").astype(str).map(_hit)


# ========= å…±è‘—ã‚¨ãƒƒã‚¸ä½œæˆï¼ˆãƒ•ã‚£ãƒ«ã‚¿å¯¾å¿œï¼‰ =========
@st.cache_data(ttl=600, show_spinner=False)
def build_coauthor_edges(df: pd.DataFrame,
                         year_from: int, year_to: int,
                         targets: List[str] | None = None,
                         types: List[str] | None = None) -> pd.DataFrame:
    """
    å…¥åŠ›: dfï¼ˆå°‘ãªãã¨ã‚‚ 'è‘—è€…', 'ç™ºè¡Œå¹´' ã‚’å«ã‚€ã“ã¨ã€‚å¯¾è±¡ç‰©/ç ”ç©¶ã‚¿ã‚¤ãƒ—ã¯ä»»æ„ï¼‰
    å‡ºåŠ›: edges DataFrame ['src', 'dst', 'weight']
    """
    use = df.copy()

    # å¹´ã§çµã‚Šè¾¼ã¿
    if "ç™ºè¡Œå¹´" in use.columns:
        y = pd.to_numeric(use["ç™ºè¡Œå¹´"], errors="coerce")
        use = use[(y >= year_from) & (y <= year_to) | y.isna()]

    # å¯¾è±¡ç‰©ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆé¸æŠå¼ï¼‰
    if targets:
        if "å¯¾è±¡ç‰©_top3" in use.columns:
            mask_tg = col_contains_any(use["å¯¾è±¡ç‰©_top3"], targets)
            use = use[mask_tg]

    # ç ”ç©¶ã‚¿ã‚¤ãƒ—ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆé¸æŠå¼ï¼‰
    if types:
        if "ç ”ç©¶ã‚¿ã‚¤ãƒ—_top3" in use.columns:
            mask_tp = col_contains_any(use["ç ”ç©¶ã‚¿ã‚¤ãƒ—_top3"], types)
            use = use[mask_tp]

    # è‘—è€…ã®ãƒšã‚¢ã‚’æ•°ãˆã‚‹
    rows: List[Tuple[str, str]] = []
    for a in use.get("è‘—è€…", pd.Series(dtype=str)).fillna(""):
        names = sorted(set(split_authors(a)))
        for s, t in itertools.combinations(names, 2):
            rows.append((s, t))

    if not rows:
        return pd.DataFrame(columns=["src", "dst", "weight"])

    edges = pd.DataFrame(rows, columns=["src", "dst"])
    edges["pair"] = edges.apply(lambda r: tuple(sorted([r["src"], r["dst"]])), axis=1)
    edges = edges.groupby("pair").size().reset_index(name="weight")
    edges[["src", "dst"]] = pd.DataFrame(edges["pair"].tolist(), index=edges.index)
    edges = edges.drop(columns=["pair"]).sort_values("weight", ascending=False).reset_index(drop=True)
    return edges[["src", "dst", "weight"]]


# ========= ä¸­å¿ƒæ€§ã‚¹ã‚³ã‚¢ =========
def centrality_from_edges(edges: pd.DataFrame, metric: str = "degree") -> pd.DataFrame:
    """
    edges: ['src','dst','weight']
    metric: 'degree'|'betweenness'|'eigenvector'
    è¿”ã‚Šå€¤: ['è‘—è€…','å…±è‘—æ•°','ã¤ãªãŒã‚Šã‚¹ã‚³ã‚¢']
    """
    if edges.empty:
        return pd.DataFrame(columns=["è‘—è€…", "å…±è‘—æ•°", "ã¤ãªãŒã‚Šã‚¹ã‚³ã‚¢"])

    # å…±è‘—æ•°ï¼ˆé‡ã¿å’Œï¼‰ã¯å¸¸ã«è¨ˆç®—
    deg_simple = pd.concat([
        edges.groupby("src")["weight"].sum(),
        edges.groupby("dst")["weight"].sum(),
    ], axis=1).fillna(0)
    deg_simple["coauth_count"] = deg_simple["weight"].sum(axis=1)
    deg_simple = deg_simple["coauth_count"].reset_index().rename(columns={"index": "è‘—è€…", "coauth_count": "å…±è‘—æ•°"})

    # networkx ãŒç„¡ã„å ´åˆã¯ç°¡æ˜“ã‚¹ã‚³ã‚¢ï¼å…±è‘—æ•°
    if not HAS_NX:
        out = deg_simple.rename(columns={"å…±è‘—æ•°": "ã¤ãªãŒã‚Šã‚¹ã‚³ã‚¢"})
        return out[["è‘—è€…", "å…±è‘—æ•°", "ã¤ãªãŒã‚Šã‚¹ã‚³ã‚¢"]].sort_values("ã¤ãªãŒã‚Šã‚¹ã‚³ã‚¢", ascending=False).reset_index(drop=True)

    # networkx ã«ã‚ˆã‚‹ä¸­å¿ƒæ€§
    G = nx.Graph()
    for _, r in edges.iterrows():
        G.add_edge(str(r["src"]), str(r["dst"]), weight=float(r["weight"]))

    if metric == "betweenness":
        cen = nx.betweenness_centrality(G, weight="weight", normalized=True)
    elif metric == "eigenvector":
        try:
            cen = nx.eigenvector_centrality_numpy(G, weight="weight")
        except Exception:
            cen = nx.degree_centrality(G)
    else:
        cen = nx.degree_centrality(G)

    cen_df = pd.Series(cen, name="ã¤ãªãŒã‚Šã‚¹ã‚³ã‚¢").reset_index().rename(columns={"index": "è‘—è€…"})
    out = pd.merge(cen_df, deg_simple, on="è‘—è€…", how="left")
    out["å…±è‘—æ•°"] = out["å…±è‘—æ•°"].fillna(0).astype(float)
    return out[["è‘—è€…", "å…±è‘—æ•°", "ã¤ãªãŒã‚Šã‚¹ã‚³ã‚¢"]].sort_values("ã¤ãªãŒã‚Šã‚¹ã‚³ã‚¢", ascending=False).reset_index(drop=True)


# ========= ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æç”»ï¼ˆPyVisï¼‰ =========
def _draw_network(edges: pd.DataFrame,
                  top_nodes: List[str] | None = None,
                  min_weight: int = 1,
                  height_px: int = 650) -> None:
    """PyVisã§æç”»ï¼ˆä»»æ„ï¼‰ã€‚ä¾å­˜ãŒç„¡ã‘ã‚Œã°ã‚¹ã‚­ãƒƒãƒ—ã€‚"""
    if not (HAS_NX and HAS_PYVIS):
        st.info("ã‚°ãƒ©ãƒ•æç”»ã«ã¯ networkx / pyvis ãŒå¿…è¦ã§ã™ã€‚è¡¨ã¯åˆ©ç”¨ã§ãã¾ã™ã€‚")
        return

    edges_use = edges[edges["weight"] >= int(min_weight)].copy()
    if edges_use.empty:
        st.warning("æ¡ä»¶ã«åˆã†ã‚¨ãƒƒã‚¸ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    G = nx.Graph()
    for _, r in edges_use.iterrows():
        s, t, w = str(r["src"]), str(r["dst"]), int(r["weight"])
        if G.has_edge(s, t):
            G[s][t]["weight"] += w
        else:
            G.add_edge(s, t, weight=w)

    if top_nodes:
        # ã‚°ãƒ©ãƒ•ã«å­˜åœ¨ã™ã‚‹ãƒãƒ¼ãƒ‰ã ã‘ã«é™å®š
        top_nodes_in = [n for n in top_nodes if n in G]
        keep = set(top_nodes_in)
        # è¿‘å‚ã‚‚å«ã‚ã‚‹ï¼ˆå­˜åœ¨ãƒã‚§ãƒƒã‚¯ä»˜ãï¼‰
        for n in top_nodes_in:
            for nbr in G.neighbors(n):
                keep.add(nbr)
        G = G.subgraph(keep).copy()
        if G.number_of_nodes() == 0:
            st.warning("ãƒˆãƒƒãƒ—NãŒã‚°ãƒ©ãƒ•ã«å­˜åœ¨ã—ã¾ã›ã‚“ã€‚æ¡ä»¶ã‚’è¦‹ç›´ã—ã¦ãã ã•ã„ã€‚")
            return

    net = Network(height=f"{height_px}px", width="100%", bgcolor="#ffffff", font_color="#222")
    net.barnes_hut(gravity=-30000, central_gravity=0.25, spring_length=110, spring_strength=0.02)
    net.from_nx(G)

    # ãƒ–ãƒ©ã‚¦ã‚¶è‡ªå‹•ã‚ªãƒ¼ãƒ—ãƒ³ã‚’é¿ã‘ã¦åŸ‹ã‚è¾¼ã¿
    html = net.generate_html(notebook=False)
    st.components.v1.html(html, height=height_px, scrolling=True)


# ========= ã‚³ãƒ”ãƒ¼ç”¨ã®è»½é‡HTMLã‚°ãƒªãƒƒãƒ‰ =========
def _render_copy_grid(authors: List[str]) -> None:
    """è¡¨ã¯å´©ã•ãšã€åˆ¥æ ã§è‘—è€…åã®ã‚³ãƒ”ãƒ¼UXã‚’æä¾›ã™ã‚‹å°ã•ãªHTMLã‚°ãƒªãƒƒãƒ‰ã€‚"""
    if not authors:
        return
    html = """
    <style>
      .copy-grid { display: grid; grid-template-columns: repeat(auto-fill, minmax(220px, 1fr)); gap: 8px; }
      .copy-chip { display:flex; align-items:center; justify-content:space-between;
                   padding:6px 10px; background:#f5f5f7; border:1px solid #ddd; border-radius:8px; font-size:13px; }
      .copy-chip button { border:none; background:#e9e9ee; padding:4px 8px; border-radius:6px; cursor:pointer; }
      .copy-chip button:hover { background:#dcdce3; }
    </style>
    <div class="copy-grid">
    """
    for name in authors:
        safe_text = str(name).replace("\\", "\\\\").replace("'", "\\'")
        html += f"""
        <div class="copy-chip">
          <span>{safe_text}</span>
          <button onclick="navigator.clipboard.writeText('{safe_text}');
                           const n=document.createElement('div');
                           n.textContent='ğŸ“‹ã€Œ{safe_text}ã€ã‚’ã‚³ãƒ”ãƒ¼ã—ã¾ã—ãŸ';
                           n.style='position:fixed;bottom:80px;right:30px;padding:10px 18px;background:#333;color:#fff;border-radius:8px;opacity:0.94;font-size:13px;z-index:9999';
                           document.body.appendChild(n); setTimeout(()=>n.remove(),1400);">
            ğŸ“‹
          </button>
        </div>
        """
    html += "</div>"
    import streamlit.components.v1 as components
    components.html(html, height=400, scrolling=True)


# ========= UIæ§‹ç¯‰ï¼ˆã‚µãƒ–ã‚¿ãƒ–å¯¾å¿œï¼‰ =========
def render_coauthor_tab(df: pd.DataFrame, use_disk_cache: bool = False):
    st.markdown("## ğŸ‘¥ ç ”ç©¶è€…ã®ã¤ãªãŒã‚Šåˆ†æï¼ˆå…±è‘—ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼‰")
    st.caption("å…±è‘—é–¢ä¿‚ãŒå¤šã„ã»ã©ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ä¸­å¿ƒã«ä½ç½®ã—ã‚„ã™ãã€æ©‹æ¸¡ã—å½¹ã‚„å½±éŸ¿åŠ›ã®å¼·ã•ã‚‚æŒ‡æ¨™ã‹ã‚‰èª­ã¿å–ã‚Œã¾ã™ã€‚")

    if df is None or "è‘—è€…" not in df.columns:
        st.warning("è‘—è€…ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return

    # ã‚¿ãƒ–æ§‹æˆï¼ˆçµŒå¹´å¤‰åŒ–ã‚µãƒ–ã‚¿ãƒ–ã¯ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒã‚ã‚‹ã¨ãã ã‘ï¼‰
    if HAS_TEMPORAL:
        tab_main, tab_temp = st.tabs(["ğŸ” ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ»ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯", "â³ çµŒå¹´å¤‰åŒ–"])
    else:
        (tab_main,) = st.tabs(["ğŸ” ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ»ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯"])

    # ===== ãƒ¡ã‚¤ãƒ³ã‚¿ãƒ– =====
    with tab_main:
        # å¹´ç¯„å›²
        if "ç™ºè¡Œå¹´" in df.columns:
            y = pd.to_numeric(df["ç™ºè¡Œå¹´"], errors="coerce")
            if y.notna().any():
                ymin, ymax = int(y.min()), int(y.max())
            else:
                ymin, ymax = 1980, 2025
        else:
            ymin, ymax = 1980, 2025

        # ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆé¸æŠå¼ï¼‰
        targets_all = sorted({w for v in df.get("å¯¾è±¡ç‰©_top3", pd.Series(dtype=str)).fillna("") for w in split_multi(v)})
        types_all   = sorted({w for v in df.get("ç ”ç©¶ã‚¿ã‚¤ãƒ—_top3", pd.Series(dtype=str)).fillna("") for w in split_multi(v)})

        c1, c2, c3= st.columns([1, 1, 1])
        with c1:
            year_from, year_to = st.slider("å¯¾è±¡å¹´ï¼ˆç¯„å›²ï¼‰", min_value=ymin, max_value=ymax, value=(ymin, ymax))
        with c2:
            tg_sel = st.multiselect("å¯¾è±¡ç‰©ã§çµã‚Šè¾¼ã¿", options=targets_all, default=[])
        with c3:
            tp_sel = st.multiselect("ç ”ç©¶ã‚¿ã‚¤ãƒ—ã§çµã‚Šè¾¼ã¿", options=types_all, default=[])

        c4, c5, c6 = st.columns([1, 1, 1])
        with c4:
            metric = st.selectbox(
                "ä¸­å¿ƒæ€§æŒ‡æ¨™",
                ["degree", "betweenness", "eigenvector"],
                index=0,
                format_func=lambda x: {
                    "degree": "æ¬¡æ•°ï¼ˆã¤ãªãŒã‚Šã®æ•°ï¼‰",
                    "betweenness": "åª’ä»‹ï¼ˆæ©‹æ¸¡ã—åº¦ï¼‰",
                    "eigenvector": "å›ºæœ‰ãƒ™ã‚¯ãƒˆãƒ«ï¼ˆå½±éŸ¿åŠ›ï¼‰",
                }[x],
                help="networkx ãŒæœªå°å…¥ã®å ´åˆã¯ç°¡æ˜“ã‚¹ã‚³ã‚¢ï¼ˆå…±è‘—æ•°ã®åˆè¨ˆï¼‰ã§ä»£æ›¿ã—ã¾ã™ã€‚",
            )
        with c5:
            top_n = st.number_input("ãƒ©ãƒ³ã‚­ãƒ³ã‚°ä»¶æ•°", min_value=5, max_value=100, value=30, step=5)
        with c6:
            min_w = st.number_input("æç”»ã™ã‚‹æœ€å°å…±è‘—å›æ•° (wâ‰¥)", min_value=1, max_value=20, value=2, step=1)

        # ---- ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰ ----
        cache_key = f"coauth_edges|{year_from}-{year_to}|tg{','.join(tg_sel)}|tp{','.join(tp_sel)}"
        edges = None
        if use_disk_cache and HAS_DISK_CACHE:
            path = cache_csv_path("coauthor_edges", cache_key)
            cached = load_csv_if_exists(path)
            if cached is not None:
                edges = cached

        if edges is None:
            edges = build_coauthor_edges(df, year_from, year_to, tg_sel, tp_sel)
            if use_disk_cache and HAS_DISK_CACHE:
                save_csv(edges, cache_csv_path("coauthor_edges", cache_key))

        if edges.empty:
            st.info("å…±è‘—é–¢ä¿‚ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚æ¡ä»¶ã‚’èª¿æ•´ã—ã¦ãã ã•ã„ã€‚")
            return

        # --- ã‚¹ã‚³ã‚¢è¡¨ç¤ºï¼ˆè¡¨ã®ä»•æ§˜ã¯ç¶­æŒï¼‰ ---
        st.markdown("### ğŸ” ç ”ç©¶è€…ã®ã¤ãªãŒã‚Šãƒ©ãƒ³ã‚­ãƒ³ã‚°")
        rank = centrality_from_edges(edges, metric=metric).head(int(top_n))
        st.dataframe(rank, use_container_width=True, hide_index=True)
        st.caption("â€» æŒ‡æ¨™ã®æ„å‘³ï¼šæ¬¡æ•°=ã¤ãªãŒã‚Šã®æ•° / åª’ä»‹=æ©‹æ¸¡ã—åº¦ / å›ºæœ‰ãƒ™ã‚¯ãƒˆãƒ«=å½±éŸ¿åŠ›ï¼ˆæœ‰åŠ›è€…ã¨ã®çµã³ä»˜ãï¼‰")

        # --- è£œåŠ©ï¼šè‘—è€…åã®ã‚¯ã‚¤ãƒƒã‚¯ã‚³ãƒ”ãƒ¼ï¼ˆåˆ¥æ ãƒ»è¡¨ã¯å´©ã•ãªã„ï¼‰ ---
        with st.expander("ğŸ“‹ è‘—è€…åã‚’ã™ãã‚³ãƒ”ãƒ¼ï¼ˆè¡¨ã¯ãã®ã¾ã¾ãƒ»è£œåŠ©æ©Ÿèƒ½ï¼‰", expanded=False):
            _render_copy_grid(rank["è‘—è€…"].tolist())

        # --- å¯è¦–åŒ–ï¼ˆé…å»¶æç”»ï¼‰ ---
        with st.expander("ğŸ•¸ï¸ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’å¯è¦–åŒ–ï¼ˆä»»æ„ãƒ»ä¾å­˜ã‚ã‚Šï¼‰", expanded=False):
            st.caption("å…±è‘—é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ã«å¯è¦–åŒ–ã—ã¾ã™ï¼ˆnetworkx / pyvis ãŒå¿…è¦ï¼‰ã€‚")
            top_only = st.toggle("ä¸Šä½ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã®å‘¨è¾ºã ã‘è¡¨ç¤ºï¼ˆè»½é‡ï¼‰", value=True)
            top_nodes = rank["è‘—è€…"].tolist() if top_only else None
            if st.button("ğŸŒ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’æç”»ã™ã‚‹"):
                _draw_network(edges, top_nodes=top_nodes, min_weight=int(min_w), height_px=700)

    # ===== ã‚µãƒ–ã‚¿ãƒ–ï¼šçµŒå¹´å¤‰åŒ– =====
    if HAS_TEMPORAL:
        with tab_temp:
            render_coauthor_temporal_subtab(df, use_disk_cache=use_disk_cache)