# modules/analysis_tab.py
# -*- coding: utf-8 -*-
"""
åˆ†æã‚¿ãƒ–ï¼ˆå…±èµ·ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼šä¸­å¿ƒæ€§ãƒ©ãƒ³ã‚­ãƒ³ã‚° + ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å¯è¦–åŒ–ï¼‰

- ä¾å­˜ã‚¼ãƒ­ã§ã€Œä¸­å¿ƒæ€§ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨ã€ã¯å‹•ä½œ
- networkx / pyvis ãŒå…¥ã£ã¦ã„ã‚Œã°ã€ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªå…±è‘—ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’æç”»ï¼ˆä»»æ„ï¼‰
"""

from __future__ import annotations
import re
import itertools
import pandas as pd
import streamlit as st

# ---- ä¾å­˜ã¯ã‚ªãƒ—ã‚·ãƒ§ãƒŠãƒ« ----
try:
    import networkx as nx  # type: ignore
    HAS_NX = True
except Exception:
    HAS_NX = False

try:
    from pyvis.network import Network  # type: ignore
    HAS_PYVIS = True
except Exception:
    HAS_PYVIS = False


# ====== å…±æœ‰ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆapp.pyå´ã¨ç‹¬ç«‹ã«å‹•ãã‚ˆã†æœ€å°å®Ÿè£…ï¼‰ ======
_AUTHOR_SPLIT_RE = re.compile(r"[;ï¼›,ã€ï¼Œ/ï¼|ï½œ]+")

def split_authors(cell) -> list[str]:
    if cell is None:
        return []
    return [w.strip() for w in _AUTHOR_SPLIT_RE.split(str(cell)) if w.strip()]

def norm_key(s: str) -> str:
    s = str(s or "")
    s = s.replace("\u00A0", " ")
    s = re.sub(r"\s+", " ", s).strip()
    return s.lower()


# ====== ãƒ‡ãƒ¼ã‚¿åŠ å·¥ ======
@st.cache_data(ttl=600, show_spinner=False)
def build_coauthor_edges(df: pd.DataFrame,
                         year_from: int | None = None,
                         year_to: int | None = None) -> pd.DataFrame:
    """
    å…¥åŠ›: dfï¼ˆå°‘ãªãã¨ã‚‚ 'è‘—è€…', 'ç™ºè¡Œå¹´' ã‚’å«ã‚€ã“ã¨ï¼‰
    å‡ºåŠ›: edges DataFrame ['src', 'dst', 'weight']
    """
    use = df.copy()
    # å¹´ã§çµã‚Šè¾¼ã¿ï¼ˆåˆ—ãŒç„¡ã„ã‚±ãƒ¼ã‚¹ã¯ãã®ã¾ã¾ï¼‰
    if "ç™ºè¡Œå¹´" in use.columns and (year_from is not None and year_to is not None):
        y = pd.to_numeric(use["ç™ºè¡Œå¹´"], errors="coerce")
        use = use[(y >= year_from) & (y <= year_to) | y.isna()]

    # è‘—è€…ã®ãƒšã‚¢ã‚’æ•°ãˆã‚‹
    rows = []
    for a in use.get("è‘—è€…", pd.Series(dtype=str)).fillna(""):
        names = split_authors(a)
        # 2åä»¥ä¸Šã®ã¨ãã«åŒä¸€è«–æ–‡å†…ã®å…¨ãƒšã‚¢ã‚’ç”Ÿæˆ
        for s, t in itertools.combinations(sorted(set(names)), 2):
            rows.append((s, t))

    if not rows:
        return pd.DataFrame(columns=["src", "dst", "weight"])

    edges = pd.DataFrame(rows, columns=["src", "dst"])
    edges["pair"] = edges.apply(lambda r: tuple(sorted([r["src"], r["dst"]])), axis=1)
    edges = (edges.groupby("pair").size()
             .reset_index(name="weight"))
    edges[["src", "dst"]] = pd.DataFrame(edges["pair"].tolist(), index=edges.index)
    edges = edges.drop(columns=["pair"]).sort_values("weight", ascending=False).reset_index(drop=True)
    return edges[["src", "dst", "weight"]]


def _centrality_from_edges(edges: pd.DataFrame, metric: str = "degree") -> pd.DataFrame:
    """
    edges: ['src','dst','weight']
    metric: 'degree'|'betweenness'|'eigenvector'
    """
    # networkx ãŒç„¡ã„å ´åˆã¯é‡ã¿ä»˜ãæ¬¡æ•°ã®ç°¡æ˜“ç‰ˆã‚’è¿”ã™
    if not HAS_NX:
        deg = pd.concat([
            edges.groupby("src")["weight"].sum(),
            edges.groupby("dst")["weight"].sum(),
        ], axis=1).fillna(0)
        deg["degree"] = deg["weight"].sum(axis=1)
        out = deg["degree"].sort_values(ascending=False).reset_index()
        out.columns = ["author", "centrality"]
        out["note"] = "degree(sum of co-auth weights) / no networkx"
        return out

    # networkx ãŒã‚ã‚‹ãªã‚‰æœ¬æ ¼è¨ˆç®—
    G = nx.Graph()
    for _, r in edges.iterrows():
        s, t, w = r["src"], r["dst"], float(r["weight"])
        if G.has_edge(s, t):
            G[s][t]["weight"] += w
        else:
            G.add_edge(s, t, weight=w)

    if metric == "betweenness":
        cen = nx.betweenness_centrality(G, weight="weight", normalized=True)
    elif metric == "eigenvector":
        try:
            cen = nx.eigenvector_centrality_numpy(G, weight="weight")
        except Exception:
            # åæŸã—ãªã„ç­‰ã®ä¾‹å¤–æ™‚ã¯æ¬¡æ•°ä¸­å¿ƒæ€§ã¸ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            cen = nx.degree_centrality(G)
    else:
        cen = nx.degree_centrality(G)

    out = (pd.Series(cen, name="centrality")
           .sort_values(ascending=False)
           .reset_index()
           .rename(columns={"index": "author"}))
    out["note"] = f"{metric} centrality"
    return out


def _draw_network(edges: pd.DataFrame,
                  top_nodes: list[str] | None = None,
                  min_weight: int = 1,
                  height_px: int = 650) -> None:
    """
    pyvis ã§æç”»ï¼ˆä»»æ„ï¼‰ã€‚ä¾å­˜ãŒç„¡ã‘ã‚Œã°ã‚¹ã‚­ãƒƒãƒ—ã€‚
    """
    if not (HAS_NX and HAS_PYVIS):
        st.info("ã‚°ãƒ©ãƒ•æç”»ã«ã¯ networkx / pyvis ãŒå¿…è¦ã§ã™ã€‚è¡¨ã¯åˆ©ç”¨ã§ãã¾ã™ã€‚")
        return

    # ã‚µãƒ–ã‚°ãƒ©ãƒ•ï¼ˆå¼·ã„ã‚¨ãƒƒã‚¸ã®ã¿ï¼‰
    edges_use = edges[edges["weight"] >= min_weight].copy()
    if edges_use.empty:
        st.warning("æ¡ä»¶ã«åˆã†ã‚¨ãƒƒã‚¸ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    G = nx.Graph()
    for _, r in edges_use.iterrows():
        G.add_edge(r["src"], r["dst"], weight=int(r["weight"]))

    if top_nodes:
        keep = set(top_nodes)
        # ãƒˆãƒƒãƒ—ï¼‹ãã®éš£æ¥ã‚’æ®‹ã™
        keep |= {nbr for n in top_nodes for nbr in G.neighbors(n)}
        G = G.subgraph(keep).copy()

    net = Network(height=f"{height_px}px", width="100%", bgcolor="#ffffff", font_color="#222")
    net.barnes_hut(gravity=-30000, central_gravity=0.2, spring_length=110, spring_strength=0.02)
    for n in G.nodes():
        net.add_node(n, label=n)
    for s, t, d in G.edges(data=True):
        w = int(d.get("weight", 1))
        net.add_edge(s, t, value=w, title=f"å…±è‘—å›æ•°: {w}")

    net.set_options("""
    {
      "nodes": {"shape": "dot", "scaling": {"min": 10, "max": 40}},
      "edges": {"smooth": false}
    }
    """)
    net.show("coauthor_network.html")
    # åŸ‹ã‚è¾¼ã¿è¡¨ç¤º
    with open("coauthor_network.html", "r", encoding="utf-8") as f:
        html = f.read()
    st.components.v1.html(html, height=height_px, scrolling=True)


# ====== ãƒ¡ã‚¤ãƒ³ã®æç”»é–¢æ•° ======
def render_analysis_tab(df: pd.DataFrame) -> None:
    st.header("ğŸ“Š åˆ†æï¼šå…±è‘—ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯")

    # å¹´ã®ç¯„å›²ï¼ˆDFã«ç„¡ã„/æ¬ æãŒå¤šã„å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
    if "ç™ºè¡Œå¹´" in df.columns:
        y = pd.to_numeric(df["ç™ºè¡Œå¹´"], errors="coerce")
        if y.notna().any():
            ymin, ymax = int(y.min()), int(y.max())
        else:
            ymin, ymax = 1980, 2025
    else:
        ymin, ymax = 1980, 2025

    c1, c2, c3, c4 = st.columns([1, 1, 1, 1])
    with c1:
        year_from, year_to = st.slider("å¯¾è±¡å¹´ï¼ˆç¯„å›²ï¼‰", min_value=ymin, max_value=ymax, value=(ymin, ymax))
    with c2:
        metric = st.selectbox("ä¸­å¿ƒæ€§", ["degree", "betweenness", "eigenvector"], index=0,
                              help="networkxæœªå°å…¥æ™‚ã¯ç°¡æ˜“degreeã®ã¿è¨ˆç®—")
    with c3:
        top_n = st.number_input("ãƒ©ãƒ³ã‚­ãƒ³ã‚°ä»¶æ•°", min_value=5, max_value=100, value=30, step=5)
    with c4:
        min_w = st.number_input("æç”»ã™ã‚‹æœ€å°å…±è‘—å›æ•° (wâ‰¥)", min_value=1, max_value=20, value=2, step=1)

    # ã‚¨ãƒƒã‚¸ä½œæˆ
    edges = build_coauthor_edges(df, year_from, year_to)

    st.markdown("#### ä¸­å¿ƒæ€§ãƒ©ãƒ³ã‚­ãƒ³ã‚°")
    if edges.empty:
        st.info("å…±è‘—ã‚¨ãƒƒã‚¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚è‘—è€…ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return

    rank = _centrality_from_edges(edges, metric=metric)
    rank = rank.head(int(top_n))
    st.dataframe(rank, use_container_width=True, hide_index=True)

    # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆä»»æ„ï¼‰
    with st.expander("ğŸŒ å…¨ä½“ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆä»»æ„ãƒ»ä¾å­˜ã‚ã‚Šï¼‰", expanded=False):
        st.caption("â€» networkx / pyvis ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹å ´åˆã®ã¿æç”»ã—ã¾ã™ã€‚")
        top_only = st.toggle("ãƒˆãƒƒãƒ—Nã®å‘¨è¾ºã ã‘å¯è¦–åŒ–ï¼ˆè»½é‡è¡¨ç¤ºï¼‰", value=True)
        top_nodes = rank["author"].tolist() if top_only else None
        draw = st.button("ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’æç”»ã™ã‚‹")
        if draw:
            _draw_network(edges, top_nodes=top_nodes, min_weight=int(min_w), height_px=700)